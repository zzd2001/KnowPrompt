/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:446: UserWarning: Checkpoint directory output exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
09/07/2024 10:49:49 - INFO - data.processor -   Writing example 0 of 810
09/07/2024 10:49:49 - INFO - data.processor -   input text : 明 日 ， 召 问 其 故 ， 曰 ： 「 [object_start] 玉 汝 [object_end] 为 [subject_start] 严 公 [subject_end] 之 使 ， 今 严 公 之 地 分 裂 ， 而 不 能 救 止 ， 无 面 目 还 报 ， 将 死 此 荒 寒 之 野 ， 是 以 哭 耳 。
09/07/2024 10:49:49 - INFO - data.processor -   prompt : [sub] 严 公 [sub] [MASK] [obj] 玉 汝 [obj] .
09/07/2024 10:49:49 - INFO - data.processor -   label : 上下级
09/07/2024 10:49:50 - INFO - data.processor -   Average #tokens: 67.49
09/07/2024 10:49:50 - INFO - data.processor -   810 (100.00 %) examples can fit max_seq_length = 128
09/07/2024 10:49:50 - INFO - data.processor -   Writing example 0 of 810
09/07/2024 10:49:50 - INFO - data.processor -   input text : 明 日 ， 召 问 其 故 ， 曰 ： 「 [object_start] 玉 汝 [object_end] 为 [subject_start] 严 公 [subject_end] 之 使 ， 今 严 公 之 地 分 裂 ， 而 不 能 救 止 ， 无 面 目 还 报 ， 将 死 此 荒 寒 之 野 ， 是 以 哭 耳 。
09/07/2024 10:49:50 - INFO - data.processor -   prompt : [sub] 严 公 [sub] [MASK] [obj] 玉 汝 [obj] .
09/07/2024 10:49:50 - INFO - data.processor -   label : 上下级
09/07/2024 10:49:50 - INFO - data.processor -   Average #tokens: 67.49
09/07/2024 10:49:50 - INFO - data.processor -   810 (100.00 %) examples can fit max_seq_length = 128
09/07/2024 10:49:50 - INFO - data.processor -   Writing example 0 of 810
09/07/2024 10:49:50 - INFO - data.processor -   input text : 明 日 ， 召 问 其 故 ， 曰 ： 「 [object_start] 玉 汝 [object_end] 为 [subject_start] 严 公 [subject_end] 之 使 ， 今 严 公 之 地 分 裂 ， 而 不 能 救 止 ， 无 面 目 还 报 ， 将 死 此 荒 寒 之 野 ， 是 以 哭 耳 。
09/07/2024 10:49:50 - INFO - data.processor -   prompt : [sub] 严 公 [sub] [MASK] [obj] 玉 汝 [obj] .
09/07/2024 10:49:50 - INFO - data.processor -   label : 上下级
09/07/2024 10:49:51 - INFO - data.processor -   Average #tokens: 67.49
09/07/2024 10:49:51 - INFO - data.processor -   810 (100.00 %) examples can fit max_seq_length = 128
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
loading..
Finish save preprocessed data to ./dataset/cached_wiki80.pkl.
loading..
Finish save preprocessed data to ./dataset/cached_wiki80.pkl.
loading..
Finish save preprocessed data to ./dataset/cached_wiki80.pkl.
  | Name    | Type             | Params
---------------------------------------------
0 | model   | RobertaForPrompt | 102 M
1 | loss_fn | CrossEntropyLoss | 0
---------------------------------------------
102 M     Trainable params
0         Non-trainable params
102 M     Total params
409.232   Total estimated model params size (MB)
/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Validation sanity check:   0%|                                                                                                   | 0/2 [00:00<?, ?it/s]--------------------------------------------
[tensor([[  101, 21144,   698,  1062, 21144,   103, 21145,  4373,  3734, 21145,
           119,   102,  3209,  3189,  8024,  1374,  7309,  1071,  3125,  8024,
          3288,  8038,   519, 21128,  4373,  3734, 21129,   711, 21130,   698,
          1062, 21131,   722,   886,  8024,   791,   698,  1062,   722,  1765,
          1146,  6162,  8024,  5445,   679,  5543,  3131,  3632,  8024,  3187,
          7481,  4680,  6820,  2845,  8024,  2199,  3647,  3634,  5774,  2170,
           722,  7029,  8024,  3221,   809,  1526,  5455,   511,   102,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0]],
       device='cuda:0'), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), tensor([2], device='cuda:0'), tensor([[2, 4, 7, 9]], device='cuda:0')]
--------------------------------------------
Validation sanity check:  50%|█████████████████████████████████████████████▌                                             | 1/2 [00:00<00:00,  1.55it/s]--------------------------------------------
[tensor([[  101, 21144,  1762,  3209, 21144,   103, 21145,  2406,  2336, 21145,
           119,   102,  3428,  6858,  7141,  8038, 21130,  1762,  3209, 21131,
          1044,   711,  2768,  2548,  1092,  4522,  1400,  8024,  5326,  2956,
         21128,  2406,  2336, 21129,  6887,  7716,  3635,  6963,  6956,  5392,
           511,   102,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0]],
       device='cuda:0'), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), tensor([6], device='cuda:0'), tensor([[2, 4, 7, 9]], device='cuda:0')]
--------------------------------------------
Epoch 0:   0%|                                                                                                      | 0/1620 [00:00<00:00, 4963.67it/s]
Global seed set to 7
/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Traceback (most recent call last):
  File "main.py", line 233, in <module>
    main()
  File "main.py", line 179, in main
    trainer.fit(lit_model, datamodule=data)
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 553, in fit
    self._run(model)
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 918, in _run
    self._dispatch()
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _dispatch
    self.accelerator.start_training(self)
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 92, in start_training
    self.training_type_plugin.start_training(trainer)
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 161, in start_training
    self._results = trainer.run_stage()
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 996, in run_stage
    return self._run_train()
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1045, in _run_train
    self.fit_loop.run()
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 111, in run
    self.advance(*args, **kwargs)
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 200, in advance
    epoch_output = self.epoch_loop.run(train_dataloader)
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 111, in run
    self.advance(*args, **kwargs)
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 131, in advance
    batch_output = self.batch_loop.run(batch, self.iteration_count, self._dataloader_idx)
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 100, in run
    super().run(batch, batch_idx, dataloader_idx)
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 111, in run
    self.advance(*args, **kwargs)
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 147, in advance
    result = self._run_optimization(batch_idx, split_batch, opt_idx, optimizer)
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 193, in _run_optimization
    closure()
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 235, in _training_step_and_backward_closure
    result = self.training_step_and_backward(split_batch, batch_idx, opt_idx, optimizer, hiddens)
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 533, in training_step_and_backward
    result = self._training_step(split_batch, batch_idx, opt_idx, hiddens)
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 306, in _training_step
    training_step_output = self.trainer.accelerator.training_step(step_kwargs)
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 193, in training_step
    return self.training_type_plugin.training_step(*step_kwargs.values())
  File "/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 172, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/root/KnowPrompt/lit_models/transformer.py", line 186, in training_step
    input_ids, attention_mask, labels, so = batch
ValueError: too many values to unpack (expected 4)