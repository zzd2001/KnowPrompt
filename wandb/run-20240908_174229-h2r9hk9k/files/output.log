/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:446: UserWarning: Checkpoint directory output exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
loading..
Finish save preprocessed data to ./dataset/cached_wiki80.pkl.
loading..
Finish save preprocessed data to ./dataset/cached_wiki80.pkl.
loading..
09/08/2024 17:42:51 - INFO - data.processor -   Writing example 0 of 810
09/08/2024 17:42:51 - INFO - data.processor -   input text : 明日，召问其故，曰：「[object_start]玉汝[object_end]为[subject_start]严公[subject_end]之使，今严公之地分裂，而不能救止，无面目还报，将死此荒寒之野，是以哭耳。
09/08/2024 17:42:51 - INFO - data.processor -   prompt : [sub]严公[sub][MASK][obj]玉汝[obj]。
09/08/2024 17:42:51 - INFO - data.processor -   label : 上下级
09/08/2024 17:42:51 - INFO - data.processor -   Average #tokens: 67.49
09/08/2024 17:42:51 - INFO - data.processor -   810 (100.00 %) examples can fit max_seq_length = 128
09/08/2024 17:42:51 - INFO - data.processor -   Writing example 0 of 810
09/08/2024 17:42:51 - INFO - data.processor -   input text : 明日，召问其故，曰：「[object_start]玉汝[object_end]为[subject_start]严公[subject_end]之使，今严公之地分裂，而不能救止，无面目还报，将死此荒寒之野，是以哭耳。
09/08/2024 17:42:51 - INFO - data.processor -   prompt : [sub]严公[sub][MASK][obj]玉汝[obj]。
09/08/2024 17:42:51 - INFO - data.processor -   label : 上下级
09/08/2024 17:42:52 - INFO - data.processor -   Average #tokens: 67.49
09/08/2024 17:42:52 - INFO - data.processor -   810 (100.00 %) examples can fit max_seq_length = 128
09/08/2024 17:42:52 - INFO - data.processor -   Writing example 0 of 810
09/08/2024 17:42:52 - INFO - data.processor -   input text : 明日，召问其故，曰：「[object_start]玉汝[object_end]为[subject_start]严公[subject_end]之使，今严公之地分裂，而不能救止，无面目还报，将死此荒寒之野，是以哭耳。
09/08/2024 17:42:52 - INFO - data.processor -   prompt : [sub]严公[sub][MASK][obj]玉汝[obj]。
09/08/2024 17:42:52 - INFO - data.processor -   label : 上下级
09/08/2024 17:42:52 - INFO - data.processor -   Average #tokens: 67.49
09/08/2024 17:42:52 - INFO - data.processor -   810 (100.00 %) examples can fit max_seq_length = 128
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Finish save preprocessed data to ./dataset/cached_wiki80.pkl.
Validation sanity check:   0%|                                                                                                 | 0/2 [00:00<?, ?it/s]--------------------------------------------
[tensor([[  101, 21144,   698,  1062, 21144,   103, 21145,  4373,  3734, 21145,
           511,   102,  3209,  3189,  8024,  1374,  7309,  1071,  3125,  8024,
          3288,  8038,   519, 21128,  4373,  3734, 21129,   711, 21130,   698,
          1062, 21131,   722,   886,  8024,   791,   698,  1062,   722,  1765,
          1146,  6162,  8024,  5445,   679,  5543,  3131,  3632,  8024,  3187,
          7481,  4680,  6820,  2845,  8024,  2199,  3647,  3634,  5774,  2170,
           722,  7029,  8024,  3221,   809,  1526,  5455,   511,   102,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0]],
       device='cuda:0'), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), tensor([2], device='cuda:0'), tensor([[2, 4, 7, 9]], device='cuda:0')]
5
--------------------------------------------
Validation sanity check:  50%|████████████████████████████████████████████▌                                            | 1/2 [00:00<00:00,  1.06it/s]--------------------------------------------
[tensor([[  101, 21144,  1762,  3209, 21144,   103, 21145,  2406,  2336, 21145,
           511,   102,  3428,  6858,  7141,  8038, 21130,  1762,  3209, 21131,
          1044,   711,  2768,  2548,  1092,  4522,  1400,  8024,  5326,  2956,
         21128,  2406,  2336, 21129,  6887,  7716,  3635,  6963,  6956,  5392,
           511,   102,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0]],
       device='cuda:0'), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
  | Name    | Type             | Params
---------------------------------------------
0 | model   | RobertaForPrompt | 102 M
1 | loss_fn | CrossEntropyLoss | 0
---------------------------------------------
102 M     Trainable params
0         Non-trainable params
102 M     Total params
409.232   Total estimated model params size (MB)
/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Global seed set to 7
/root/.conda/envs/knowprompt/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Using bos_token, but it is not set yet.
